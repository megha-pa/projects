{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[\"Order Date\",\"Product ID\",\"Sales\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATE_COL = \"Order Date\"\n",
    "ID_COL=\"Product ID\"\n",
    "TARGET_COL = \"Sales\"\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL])\n",
    "FORECAST_HORIZON=18\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "monthly_aggrigated_ecommerce_data=pd.DataFrame()\n",
    "        \n",
    "        \n",
    "for article in df[ID_COL].unique():\n",
    "    sub_df = df[(df[ID_COL]==article)]\n",
    "    end_date_last_day = sub_df[DATE_COL].max().replace(day=1) - timedelta(days=1)\n",
    "    \n",
    "\n",
    "    #end_date_last_day = date.today().replace(day=1) - timedelta(days=1)\n",
    "    \n",
    "    end_date_last_day=pd.to_datetime(end_date_last_day)\n",
    "\n",
    "\n",
    "#filter out the transactions or drop current month demand as it is progressively get updated\n",
    "    sub_df = sub_df[(sub_df[DATE_COL] <= end_date_last_day)]\n",
    "    if not(sub_df.empty):\n",
    "        sub_df_copy = sub_df.copy()\n",
    "        #add a record to fill 0s for discontinued product untill last month\n",
    "        if(sub_df[DATE_COL].max() < end_date_last_day):\n",
    "            record_to_insert = {ID_COL: article, DATE_COL: end_date_last_day, TARGET_COL : 0} #populate a dummy record of last month so that resampling function handles filling 0s for discontinued products \n",
    "            sub_df = sub_df.append(record_to_insert, ignore_index=True)\n",
    "\n",
    "        #sub_df = sub_df.append(generate_forecast_window(end_date_last_day, FORECAST_HORIZON, article, customer, cost=sub_df[\"COST\"].iloc[-1]), ignore_index=True)\n",
    "        #df['date'] = pd.to_datetime(df['date'])\n",
    "        sub_df[DATE_COL]=pd.to_datetime(sub_df[DATE_COL])\n",
    "        sub_df.index = sub_df[DATE_COL]\n",
    "        sub_df = sub_df.resample(rule='MS').agg({'Sales' : 'sum'})\n",
    "        sub_df = sub_df.reset_index()\n",
    "        sub_df[ID_COL] = article  \n",
    "        monthly_aggrigated_ecommerce_data = monthly_aggrigated_ecommerce_data.append(sub_df, ignore_index=True)\n",
    "\n",
    "monthly_aggrigated_ecommerce_data.to_csv(\"output.csv\",index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_aggrigated_ecommerce_data[ID_COL].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monthly_aggrigated_ecommerce_data =monthly_aggrigated_ecommerce_data[monthly_aggrigated_ecommerce_data[ID_COL] == \"FUR-BO-10001798\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_time_series_for_modeling(df, evaluation_size):\n",
    "            import pandas as pd \n",
    "            import numpy as np\n",
    "            train_size = len(df) - evaluation_size\n",
    "            train, eval = df.iloc[:train_size], df.iloc[train_size:]\n",
    "            return train, eval\n",
    "train_df1=pd.DataFrame()\n",
    "eval_df1=pd.DataFrame()\n",
    "        \n",
    "for article in monthly_aggrigated_ecommerce_data[ID_COL].unique():\n",
    "    single_article_df = monthly_aggrigated_ecommerce_data[monthly_aggrigated_ecommerce_data[ID_COL] == article]\n",
    "    if not(single_article_df.empty):\n",
    "        train_df, evaluation_df = split_time_series_for_modeling(single_article_df, evaluation_size = 6) #Need to applied in component 2 and only train, test dfs need to be there\n",
    "        train_df1=train_df1.append(train_df)\n",
    "        eval_df1=eval_df1.append(evaluation_df)\n",
    "    #train_df1.to_csv(train_df_path.path,index = False)\n",
    "    #eval_df1.to_csv(validation_df_path.path,index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in monthly_aggrigated_ecommerce_data[ID_COL].unique():\n",
    "    single_article_training_df =train_df1[train_df1[ID_COL] == article]\n",
    "    single_article_evaluation_df = eval_df1[eval_df1[ID_COL] == article]\n",
    "   \n",
    "    article_df=single_article_training_df.append(single_article_evaluation_df,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "import datetime\n",
    "def ceil_list_of_values(values):\n",
    "    return np.ceil(values)\n",
    "\n",
    "def generate_dates(last_date, horizon):\n",
    "    print(\"generate dates started!!!\")\n",
    "    dates_list = list(pd.date_range(start=last_date , periods=horizon + 1,freq=\"M\"))\n",
    "    print(\"dates SUCESSFUL!!!\")\n",
    "    return dates_list[1:]\n",
    "\n",
    "def generate_algorithm_results_df(eval_df, model_predictions, model_forecasts, algorithm_name):\n",
    "        FORECAST_HORIZON=18\n",
    "        print(\"algorithem started!!!\")\n",
    "        eval_df[TARGET_COL+\"_PREDICTED\"] = model_predictions\n",
    "        last_date = eval_df[DATE_COL].values.tolist()[-1] #last date\n",
    "        projected_dates = generate_dates(last_date, FORECAST_HORIZON)\n",
    "        forecast_df = pd.DataFrame()\n",
    "        forecast_df[DATE_COL] = projected_dates\n",
    "        forecast_df[ID_COL] = eval_df[ID_COL].values[0]\n",
    "        #forecast_df[\"CUSTOMER_NAME\"] = eval_df[\"CUSTOMER_NAME_\"].values[0] #comment for primary and secondary retail\n",
    "        forecast_df[TARGET_COL+\"_Forecasted\"] = np.ceil(model_forecasts)\n",
    "        final_outcome_df = pd.concat([eval_df, forecast_df], axis=0)\n",
    "        final_outcome_df[\"MODEL\"] = algorithm_name\n",
    "        print(\"algorithem SUCESSFUL!!!\")\n",
    "        return final_outcome_df\n",
    "\n",
    "def ma_train_with_optimal_parameters(best_window, article_df):\n",
    "        series = article_df[TARGET_COL].values.tolist()\n",
    "        preds = [] #to append predictions\n",
    "        for t in range(FORECAST_HORIZON):\n",
    "            length = len(series)\n",
    "            forecast = np.mean([series[i] for i in range(length - best_window, length)])\n",
    "\n",
    "            #append the forecast to the history and predictions\n",
    "            series.append(forecast)\n",
    "            preds.append(forecast)   \n",
    "        return preds\n",
    "\n",
    "def MAMODEL(train, evaluation, article_df):\n",
    "    best_rmse = float('inf')\n",
    "    best_window = None\n",
    "    evaluation_predictions = None\n",
    "    test_data = None\n",
    "    data_length = len(article_df[TARGET_COL].values.tolist())\n",
    "    windows = [x for x in range(2, data_length // 2)]\n",
    "    \n",
    "\n",
    "    #iterate through windows\n",
    "    for window in windows:\n",
    "        #history and test series\n",
    "        series = article_df[TARGET_COL].values.tolist()\n",
    "        history = [series[i] for i in range(window)]\n",
    "        test = [series[i] for i in range(window, len(series))]\n",
    "\n",
    "        predictions = [] #predictions\n",
    "\n",
    "        #walk forward over time steps in test data\n",
    "        for t in range(len(test)):\n",
    "            length = len(history)\n",
    "            yhat = np.mean([history[i] for i in range(length-window, length)])\n",
    "            obs = test[t]\n",
    "\n",
    "            predictions.append(yhat)\n",
    "            history.append(obs)\n",
    "\n",
    "        #error rate\n",
    "        error_rate = np.sqrt(mean_squared_error(test, predictions))\n",
    "\n",
    "        #best parameters\n",
    "        if best_rmse >= error_rate:\n",
    "            best_rmse = error_rate\n",
    "            evaluation_predictions = predictions\n",
    "            best_window = window\n",
    "            test_data = test\n",
    "\n",
    "    forecast_predictions =  ma_train_with_optimal_parameters(best_window, article_df)   \n",
    "    evaluation_predictions = ceil_list_of_values(evaluation_predictions[-len(evaluation):])\n",
    "    forecast_predictions = ceil_list_of_values(forecast_predictions)\n",
    "    return evaluation_predictions, forecast_predictions\n",
    "\n",
    "algorithem_df=pd.DataFrame()\n",
    "for article in monthly_aggrigated_ecommerce_data[ID_COL].unique():\n",
    "    print(article)\n",
    "    single_article_training_df =train_df1[train_df1[ID_COL] == article]\n",
    "    single_article_evaluation_df = eval_df1[eval_df1[ID_COL] == article]\n",
    "    try:\n",
    "        \n",
    "        article_df=single_article_training_df.append(single_article_evaluation_df,ignore_index=True)\n",
    "\n",
    "        model_evaluation_predictions, model_forecast_predictions =  MAMODEL(single_article_training_df, single_article_evaluation_df, article_df)\n",
    "        print(\"fg\")\n",
    "        algorithm_results = generate_algorithm_results_df(single_article_evaluation_df, model_evaluation_predictions, model_forecast_predictions, \"MA\")\n",
    "        algorithem_df=algorithem_df.append(algorithm_results,ignore_index=True)\n",
    "        print(algorithm_results)\n",
    "        print(algorithem_df.head())\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "algorithem_df.to_csv(\"algo_df.csv\",index = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg=pd.read_csv(\"algo_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
